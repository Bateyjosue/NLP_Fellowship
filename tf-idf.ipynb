{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqBtSEqxRBhDPi3ddnsh3G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bateyjosue/NLP_Fellowship/blob/main/tf-idf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In-class practicals\n",
        "Create a class using code above"
      ],
      "metadata": {
        "id": "xXgUJ1r5ufdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "metadata": {
        "id": "rAXTqx2DUVkT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TDIDF:\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.word_to_index = {}\n",
        "        self.index_to_word = {}\n",
        "        self.idf = {}\n",
        "        self.num_documents = 0\n",
        "        \n",
        "\n",
        "    def term_frequency(self,sentence):\n",
        "        word_dict = {}\n",
        "        for word in sentence.split():\n",
        "          word_dict[word] = word_dict.get(word, 0) + 1\n",
        "        return word_dict\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        # Enter code here. It will involve getting the idf and the word_to_index. Returns nothing\n",
        "        word_dict = {}\n",
        "        global_freq = {}\n",
        "        for sentence in data:\n",
        "          for word in sentence.split():\n",
        "            word_dict[word] = word_dict.get(word, 0) + 1\n",
        "\n",
        "          for word in word_dict:\n",
        "            global_freq[word] = global_freq.get(word, 0) + 1\n",
        "\n",
        "        for word, freq in global_freq.items():\n",
        "          self.idf[word] = math.log((1 + len(data)/(1 + freq)))\n",
        "          document = list(global_freq.keys())\n",
        "          for position in range(len(document)):\n",
        "            word = document[position]\n",
        "            self.word_to_index[word] = position\n",
        "            self.index_to_word[position] = word\n",
        "\n",
        "\n",
        "\n",
        "    def transform(self, data):\n",
        "        if isinstance(data,list):\n",
        "            return self._transform_document(data)\n",
        "        elif isinstance(data,str):\n",
        "            return self._tranform_sentence(data)\n",
        "\n",
        "    def _transform_document(self,data):\n",
        "        #used for processing multiple sentences\n",
        "        sentence_arrays = []\n",
        "        sentence_tf_idf = {}\n",
        "        document_freq = {}\n",
        "\n",
        "        for sent in data:\n",
        "          tokens = [token for foken in sent.split()]\n",
        "          word_array = np.zeros(len(self.word_to_index))\n",
        "          for word in tokens:\n",
        "            document_freq[word] = document_freq.get(word, 0) + 1\n",
        "          \n",
        "          total_words = sum(document_freq.values())\n",
        "          averaged_freq = {k:(float(v)/total_words) for k,v in document_freq.items()}\n",
        "\n",
        "          for term, tf in averaged_freq.items():\n",
        "            sentence_tf_idf[term] = tf * self.idf.get(term, 0)\n",
        "\n",
        "          for token in tokens:\n",
        "            if token in self.word_of_index:\n",
        "              token_index = self.word_to_index[token]\n",
        "              word_array[token_index] = sentence_tf_idf[token]\n",
        "          \n",
        "          sentence_arrays.append(word_array)\n",
        "        return np.matrix(sentence_arrays)\n",
        "\n",
        "    def _tranform_sentence(self,data):\n",
        "        # given a sentence get the average frequency and multiply it with the idf. \n",
        "        # Then place the values in the word array\n",
        "        document_freq = {}\n",
        "        sentence_tf_idf = {}\n",
        "        word_array = np.zeros(len(self.word_to_index))\n",
        "        for word in data.split():\n",
        "          document_freq[word] = document_freq.get(word, 0) + 1\n",
        "        \n",
        "        total_words = sum(document_freq.values())\n",
        "        averaged_freq = {k:(float(v)/total_words) for k,v in document_freq.items()}\n",
        "        \n",
        "        for term, tf in averaged_freq.items():\n",
        "          sentence_tf_idf[term] = tf * self.idf.get(term, 0)\n",
        "\n",
        "        for token in data.split():\n",
        "          if token in self.word_to_index:\n",
        "            token_index = self.word_to_index[token]\n",
        "            word_array[token_index] = sentence_tf_idf[token]\n",
        "        return word_array\n",
        "\n",
        "    def _compute_sentence_tf_idf(self, sentence):\n",
        "        \"\"\"\n",
        "        Computes the tf_idf for a single sentence(document).\n",
        "        \"\"\"\n",
        "        sentence_tf_idf = {}\n",
        "        # Gets the document frequency by using the helper method\n",
        "        document_frequency = self.term_frequency(sentence, self.ignore_tokens, self.lower_case)\n",
        "        # Gets the total number of words in sentence\n",
        "        total_words = sum(document_frequency.values())\n",
        "        # Find individual term frequency value averaged by total number of words.\n",
        "        averaged_frequency = {k:(float(v)/total_words) for k,v in document_frequency.items()}\n",
        "        \n",
        "        for term, tf in averaged_frequency.items():\n",
        "            # Out of vocabulary words are simply zeroed. They are going to be removed later either way.\n",
        "            # Computes the tfidf for each word by using word tf times the term idf\n",
        "            sentence_tf_idf[term] = tf*self.idf.get(term, 0)\n",
        "        return sentence_tf_idf"
      ],
      "metadata": {
        "id": "vaoIzRQ7uhkN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing your code\n",
        "tdidf = TDIDF()\n",
        "tdidf.fit(['this is a list of sentences', 'second sentence in list of sentences', 'a word for complexity'])\n",
        "print(tdidf.word_to_index)\n",
        "print(tdidf.idf)\n",
        "print(tdidf.transform(\"this is a sentence with two words sentence in\")) # it should pick either sentence or array of sentences"
      ],
      "metadata": {
        "id": "0LXCUvk3umoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9854a5ba-9e11-42a4-b734-5e5b9ad0b249"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'this': 0, 'is': 1, 'a': 2, 'list': 3, 'of': 4, 'sentences': 5, 'second': 6, 'sentence': 7, 'in': 8, 'word': 9, 'for': 10, 'complexity': 11}\n",
            "{'this': 0.5596157879354227, 'is': 0.5596157879354227, 'a': 0.5596157879354227, 'list': 0.5596157879354227, 'of': 0.5596157879354227, 'sentences': 0.5596157879354227, 'second': 0.6931471805599453, 'sentence': 0.6931471805599453, 'in': 0.6931471805599453, 'word': 0.9162907318741551, 'for': 0.9162907318741551, 'complexity': 0.9162907318741551}\n",
            "[0.06217953 0.06217953 0.06217953 0.         0.         0.\n",
            " 0.         0.15403271 0.07701635 0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment\n",
        "\n",
        "\n",
        "*   Compare results with sklearn package: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
        "*   Use the code above on the cleaned text"
      ],
      "metadata": {
        "id": "sZvxghHLuo1W"
      }
    }
  ]
}